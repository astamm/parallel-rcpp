---
title: "Hausdorff Distance Matrix Computation"
author: "Aymeric Stamm"
format: html
execute:
  cache: true
---

```{r setup}
#| include: false
#| cache: false
mfdat <- readRDS("mfdat.rds")
dat <- readRDS("dat.rds")
library(purrr)
library(rlang)
library(roahd)
Rcpp::sourceCpp("hausdorff.cpp")
```

## Data & Goal

We have simulated 3D functional data for this lab that is provided in the Quarto
document in the `dat` object.

The `dat` object is a list of size $100$ containing $100$ three-dimensional
curves observed on a common grid of size $200$ of the interval $[0, 1]$.

As a result, each element of the `dat` list is a $3 \times 200$ matrix.

The data looks like this:

```{r data-viz}
#| cache: true
plot(mfdat)
```

::: {.callout-tip icon=false}
## Objective

The goal is to implement a function similar to `stats::dist()` which computes
the pairwise distance matrix on this functional dataset using the Hausdorff
distance.
:::

## Hausdorff distance in R

We can implement the Hausdorff distance between two curves as:

```{r hausdorff_distance_vec}
hausdorff_distance_vec <- function(x, y) {
  P <- ncol(x)
  dX <- 1:P |>
    purrr::map_dbl(\(p) {
      min(colSums((y - x[, p])^2))
    }) |>
    max()
  dY <- 1:P |>
    purrr::map_dbl(\(p) {
      min(colSums((x - y[, p])^2))
    }) |>
    max()
  sqrt(max(dX, dY))
}
```

This version exploits the vectorized nature of R to compute the Hausdorff
distance via calls to `colSums()` and `max()`. Another version based on a double
loop is provided by the following `hausdorff_distance_for()` function:

```{r hausdorff_distance_for}
hausdorff_distance_for <- function(x, y) {
  P <- ncol(x)
  dX <- 0
  dY <- 0
  for (i in 1:P) {
    min_dist_x <- Inf
    min_dist_y <- Inf
    for (j in 1:P) {
      dist_x <- sum((y[, j] - x[, i])^2)
      if (dist_x < min_dist_x) {
        min_dist_x <- dist_x
      }
      dist_y <- sum((x[, j] - y[, i])^2)
      if (dist_y < min_dist_y) {
        min_dist_y <- dist_y
      }
    }
    if (min_dist_x > dX) {
      dX <- min_dist_x
    }
    if (min_dist_y > dY) {
      dY <- min_dist_y
    }
  }
  sqrt(max(dX, dY))
}
```

We can benchmark the two versions:

```{r}
bm <- bench::mark(
  hausdorff_distance_vec(dat[[1]], dat[[2]]),
  hausdorff_distance_for(dat[[1]], dat[[2]])
)
bm |> 
  dplyr::select(expression, median, mem_alloc) |> 
  dplyr::mutate(
    expression = purrr::map_chr(expression, deparse),
    median = as.numeric(median) * 1000,
    mem_alloc = as.numeric(mem_alloc)
  ) |>
  gt::gt() |>
  gt::cols_label(
    expression = gt::md("**Expression**"),
    median = gt::md("**Median computation time**"),
    mem_alloc = gt::md("**Memory allocation**")
  ) |>
  gt::cols_align(align =  "left", columns = expression) |>
  gt::cols_align(align = "right", columns = median:mem_alloc) |>
  gt::cols_align_decimal() |>
  gt::fmt_number(columns = "median", decimals = 2, pattern = "{x} ms") |>
  gt::fmt_bytes(columns = "mem_alloc")
```

We conclude that the vectorized version is faster but has a huge memory
footprint compared to the loop-based version. This means that the vectorized
version is not suitable for even moderately large data sets.

## Pairwise distance matrix in R

::: {.callout-tip}
## dist objects

Take a look at the documentation of the `stats::dist()` function to understand
how to make an object of class `dist`.
:::

We can exploit the previous functions to compute the pairwise distance matrix
using the Hausdorff distance:

```{r dist_r_v1}
dist_r_v1 <- function(x, vectorized = FALSE) {
  hausdorff_distance <- if (vectorized) 
    hausdorff_distance_vec
  else 
    hausdorff_distance_for
  N <- length(x)
  out <- 1:(N - 1) |>
    purrr::map(\(i) {
      purrr::map_dbl((i + 1):N, \(j) {
        hausdorff_distance(x[[i]], x[[j]])
      })
    }) |>
    purrr::list_c()

  attributes(out) <- NULL
  attr(out, "Size") <- N
  lbls <- names(x)
  attr(out, "Labels") <- if (is.null(lbls)) 1:N else lbls
  attr(out, "Diag") <- FALSE
  attr(out, "Upper") <- FALSE
  attr(out, "method") <- "hausdorff"
  class(out) <- "dist"
  out
}
```

We can benchmark the two versions:

```{r}
bm <- bench::mark(
  dist_r_v1(dat[1:20], vectorized = TRUE),
  dist_r_v1(dat[1:20], vectorized = FALSE)
)
bm |> 
  dplyr::select(expression, median, mem_alloc) |> 
  dplyr::mutate(
    expression = purrr::map_chr(expression, deparse),
    median = as.numeric(median),
    mem_alloc = as.numeric(mem_alloc)
  ) |>
  gt::gt() |>
  gt::cols_label(
    expression = gt::md("**Expression**"),
    median = gt::md("**Median computation time**"),
    mem_alloc = gt::md("**Memory allocation**")
  ) |>
  gt::cols_align(align =  "left", columns = expression) |>
  gt::cols_align(align = "right", columns = median:mem_alloc) |>
  gt::cols_align_decimal() |>
  gt::fmt_number(columns = "median", decimals = 2, pattern = "{x} s") |>
  gt::fmt_bytes(columns = "mem_alloc")
```

::: {.callout-tip}
## Memory footprint

We confirm that the vectorized version is not scalable to large datasets. Using
it on the full dataset actually requires 12GB of memory! We will therefore focus
on the loop-based version from now on.
:::

## futureverse

### Parallelize outer loop

```{r dist_r_v2}
dist_r_v2 <- function(x) {
  N <- length(x)
  out <- 1:(N - 1) |>
    furrr::future_map(\(i) {
      purrr::map_dbl((i + 1):N, \(j) {
        hausdorff_distance_for(x[[i]], x[[j]])
      })
    }) |>
    purrr::list_c()

  attributes(out) <- NULL
  attr(out, "Size") <- N
  lbls <- names(x)
  attr(out, "Labels") <- if (is.null(lbls)) 1:N else lbls
  attr(out, "Diag") <- FALSE
  attr(out, "Upper") <- FALSE
  attr(out, "method") <- "hausdorff"
  class(out) <- "dist"
  out
}
```

### Tweaking the chunk size

```{r dist_r_v3}
dist_r_v3 <- function(x) {
  N <- length(x)
  out <- 1:(N - 1) |>
    furrr::future_map(\(i) {
      purrr::map_dbl((i + 1):N, \(j) {
        hausdorff_distance_for(x[[i]], x[[j]])
      })
    }, .options = furrr::furrr_options(chunk_size = 1)) |>
    purrr::list_c()

  attributes(out) <- NULL
  attr(out, "Size") <- N
  lbls <- names(x)
  attr(out, "Labels") <- if (is.null(lbls)) 1:N else lbls
  attr(out, "Diag") <- FALSE
  attr(out, "Upper") <- FALSE
  attr(out, "method") <- "hausdorff"
  class(out) <- "dist"
  out
}
```

### Nested plan

```{r dist_r_v4}
dist_r_v4 <- function(x) {
  N <- length(x)
  out <- 1:(N - 1) |>
    furrr::future_map(\(i) {
      furrr::future_map_dbl((i + 1):N, \(j) {
        hausdorff_distance_for(x[[i]], x[[j]])
      })
    }, .options = furrr::furrr_options(chunk_size = 1)) |>
    purrr::list_c()

  attributes(out) <- NULL
  attr(out, "Size") <- N
  lbls <- names(x)
  attr(out, "Labels") <- if (is.null(lbls)) 1:N else lbls
  attr(out, "Diag") <- FALSE
  attr(out, "Upper") <- FALSE
  attr(out, "method") <- "hausdorff"
  class(out) <- "dist"
  out
}
```

### Convert to single loop

```{r dist_r_v5}
dist_r_v5 <- function(x) {
  N <- length(x)
  K <- N * (N - 1) / 2
  out <- furrr::future_map_dbl(1:K, \(k) {
    k <- k - 1
    i <- N - 2 - floor(sqrt(-8 * k + 4 * N * (N - 1) - 7) / 2.0 - 0.5);
    j <- k + i + 1 - N * (N - 1) / 2 + (N - i) * ((N - i) - 1) / 2;
    i <- i + 1
    j <- j + 1
    hausdorff_distance_for(x[[i]], x[[j]])
  })
  attributes(out) <- NULL
  attr(out, "Size") <- N
  lbls <- names(x)
  attr(out, "Labels") <- if (is.null(lbls)) 1:N else lbls
  attr(out, "Diag") <- FALSE
  attr(out, "Upper") <- FALSE
  attr(out, "method") <- "hausdorff"
  class(out) <- "dist"
  out
}
```

### Benchmark

```{r}
library(future)

bm <- bench::mark(
  sequential = dist_r_v1(dat[1:21], vectorized = FALSE),
  outer = {
    plan(multisession, workers = 5L)
    out <- dist_r_v2(dat[1:21])
    plan(sequential)
    out
  },
  chunksize = {
    plan(multisession, workers = 5L)
    out <- dist_r_v3(dat[1:21])
    plan(sequential)
    out
  },
  nested1 = {
    plan(list(
      tweak(multisession, workers = 2L),
      tweak(multisession, workers = I(3L))
    ))
    out <- dist_r_v4(dat[1:21])
    plan(sequential)
    out
  },
  nested2 = {
    plan(list(
      tweak(multisession, workers = 3L),
      tweak(multisession, workers = I(2L))
    ))
    out <- dist_r_v4(dat[1:21])
    plan(sequential)
    out
  },
  nested3 = {
    plan(list(
      tweak(multisession, workers = 5L),
      tweak(multisession, workers = I(2L))
    ))
    out <- dist_r_v4(dat[1:21])
    plan(sequential)
    out
  },
  singleloop = {
    plan(multisession, workers = 5L)
    out <- dist_r_v5(dat[1:21])
    plan(sequential)
    out
  },
  openmp1 = dist_cpp_omp(dat[1:21], dimension = 3L, ncores = 1L),
  openmp5 = dist_cpp_omp(dat[1:21], dimension = 3L, ncores = 5L),
  rcppparallel1 = dist_rcppparallel(dat[1:21], dimension = 3L, ncores = 1L),
  rcppparallel5 = dist_rcppparallel(dat[1:21], dimension = 3L, ncores = 5L)
)

bm |> 
  dplyr::select(expression, median, mem_alloc) |> 
  dplyr::mutate(
    lang = c(rep("R", 7), rep("C++", 4)),
    expression = names(expression),
    median = as.numeric(median) * 1000,
    mem_alloc = as.numeric(mem_alloc)
  ) |>
  dplyr::select(lang, expression, median, mem_alloc) |>
  gt::gt() |>
  gt::cols_label(
    lang = gt::md("**Language**"),
    expression = gt::md("**Expression**"),
    median = gt::md("**Median computation time**"),
    mem_alloc = gt::md("**Memory allocation**")
  ) |>
  gt::cols_align(align =  "left", columns = lang:expression) |>
  gt::cols_align(align = "right", columns = median:mem_alloc) |>
  gt::cols_align_decimal(columns = median:mem_alloc) |>
  gt::fmt_number(columns = "median", decimals = 2, pattern = "{x} ms") |>
  gt::fmt_bytes(columns = "mem_alloc") |> 
  gt::tab_header(
    title = "Comparison of different implementations",
    subtitle = "The computation time is given in milliseconds and the memory allocation in bytes."
  ) |> 
  # Add line color based on language
  gt::tab_style(
    style = gt::cell_fill(color = "lightskyblue1"),
    locations = gt::cells_body(rows = lang == "R")
  ) |>
  gt::tab_style(
    style = gt::cell_fill(color = "lightgoldenrod1"),
    locations = gt::cells_body(rows = lang == "C++")
  ) |> 
  # Color the header
  gt::tab_style(
    style = gt::cell_fill(color = "lightgray"),
    locations = gt::cells_column_labels()
  )
```

## Interpretation

**General observation.** Using C++ is much faster than using R. This is in
particular due to never copying the data. It also provides linear speed-up as
expected.

**R implementation.** The original Hausdorff distance implementation has a
double loop.

- The outer loop generates unbalanced chunks, which is not optimal (`outer`
entry).
- Load balancing is better with a fixed chunk size of 1 (`chunksize` entry). 
- Using nested parallelization does not help (`nested1`, `nested2`, `nested3`
entries).
- Transforming the original double loop into a single loop (`singleloop` entry)
is as fast as parallelizing the outer loop using a chunk size of 1 (`singleloop`
entry) but its memory allocation is much lower. This is because, when the chunk
size is 1, a future is created for each iteration of the loop, and the whole
data is copied for each future. In contrast, the single loop version only copies
the data once.
- In general, playing with chunk size and nested parallelization generates more
future objects and copies the data more often, which increases memory allocation.
